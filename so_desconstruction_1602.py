# -*- coding: utf-8 -*-
"""SOM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mJe1Tmv6ZtIy0UGMYtFKce8Lw1EEVlza
"""

#!pip install SimpSOM

import pandas as pd

from sklearn.tree import  DecisionTreeClassifier,export_graphviz
from sklearn.model_selection import train_test_split
from sklearn import metrics
import numpy as np
import SimpSOM as sps
from sklearn.preprocessing import normalize
from sklearn.preprocessing import normalize
import random

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from adaline_opt import adaline_func, generate_adaline_features

def map_class(row):
  return row
  # if(row == "tested_negative"):
  #   return 0
  # return 1

df_diabetes = pd.read_csv("./datasets/sonar.csv")
df_diabetes["class"] = df_diabetes["class"].apply(map_class)
df_diabetes.head()

accuracy_array_normal = []
accuracy_array_desc = []

for x in range(30):
  X_train, X_test, y_train, y_test = train_test_split(df_diabetes.drop('class',axis=1),df_diabetes['class'],test_size=0.3,stratify=df_diabetes['class'])
  X_train = normalize(X_train)
  X_test = normalize(X_test)
  X_train.shape,X_test.shape

  df_describe = pd.DataFrame(y_test)
  print(df_describe.describe())


  X_train_SOM_N, X_train_SOM, y_train_SOM_N, y_train_SOM = train_test_split(X_train,y_train,test_size=0.2, stratify=y_train)

  X_train_SOM_N.shape, X_train_SOM.shape

  net = sps.somNet(6, 6, X_train_SOM, PBC=True)
  net.train(0.01, 10000)
  net.save('weights_1')
 

  def automatic_transformation(dataframe,weights="flename_weights"):
    weights = np.load("./"+weights+".npy")
    new_data = []
    for data in dataframe:
      new_features = []
      for i,w in enumerate(weights):
        if i == 0:
          continue
        new_features.append(
            sum([x*data[i] for i,x in enumerate(w)])
        )
      new_data.append(np.concatenate(([],new_features)))
    return new_data


  new_X_train_1 = normalize(automatic_transformation(X_train_SOM_N,'weights_1'))

  net2 = sps.somNet(5, 5, X_train_SOM, PBC=True)
  net2.train(0.01, 10000)
  net2.save('weights_2')
  new_X_train_2 = normalize(automatic_transformation(X_train_SOM_N, "weights_2"))

  net3 = sps.somNet(4, 4, X_train_SOM, PBC=True)
  net3.train(0.01, 10000)
  net3.save('weights_3')

  new_X_train_3 = normalize(automatic_transformation(X_train_SOM_N, "weights_3"))
  adaline_weight = None

  def generate_adversarial_new_features(feature_type, qt, inputs=[]):
    new_feature = []
    if adaline_weight is None : 
      for x in range(0, qt):
        new_values = []
        for i in range(0,10):
          new_values.append(random.uniform(1,-1))
        new_feature.append(new_values)
    else:
      for x in inputs:
        new_feature.append(generate_adaline_features(x, adaline_weight))
    return new_feature

    
  for i in range(0, 10):
    ##construir if
      X_train_pot, X_test_pot, y_train_pot, y_test_pot = train_test_split(X_train_SOM,y_train_SOM,test_size=0.3,stratify=y_train_SOM)

      
      new_X_train_1_pot = normalize(automatic_transformation(X_train_pot, 'weights_1'))
      new_X_train_2_pot = normalize(automatic_transformation(X_train_pot, 'weights_2'))
      new_X_train_3_pot = normalize(automatic_transformation(X_train_pot, 'weights_3'))

      new_X_test_1_pot = normalize(automatic_transformation(X_test_pot, 'weights_1'))
      new_X_test_2_pot = normalize(automatic_transformation(X_test_pot, 'weights_2'))
      new_X_test_3_pot = normalize(automatic_transformation(X_test_pot, 'weights_3'))

      new_X_train_pot = []
      for i,x in enumerate(X_train_pot):
        new_X_train_pot.append(np.concatenate((
          x,
          new_X_train_1_pot[i],
          new_X_train_2_pot[i],
          new_X_train_3_pot[i]
        )))
      adversarial_train_features = generate_adversarial_new_features(feature_type="random", qt=len(X_train_pot),inputs=new_X_train_pot)
      new_X_train_pot = [np.concatenate((x,new_X_train_pot[i])) for i,x in enumerate(adversarial_train_features)]
      
      new_X_test_pot = []
      for i,x in enumerate(X_test_pot):
        new_X_test_pot.append(np.concatenate((
          x,
          new_X_test_1_pot[i],
          new_X_test_2_pot[i],
          new_X_test_3_pot[i]
        )))
      adversarial_test_features = generate_adversarial_new_features(feature_type="random", qt=len(X_test_pot),inputs=new_X_test_pot)
      new_X_test_pot = [np.concatenate((x,new_X_test_pot[i])) for i,x in enumerate(adversarial_test_features)]
      
    
      #from sklearn.neural_network import MLPClassifier
      ## Model to replace

      from sklearn.ensemble import RandomForestClassifier

      clf = RandomForestClassifier()
      clf.fit(new_X_train_pot, y_train_pot)

      ## fim
      results = clf.predict(new_X_test_pot)
      old_accuracy = metrics.f1_score(y_test_pot,results)
      print("LEN", len(new_X_train_pot[0]))
      
      def target_function(new_features, old_features,clf):
        values_to_predict = []
        for i,nf in enumerate(new_features):
          values_to_predict.append(np.concatenate((nf,old_features[i][10:])))
        results = clf.predict(values_to_predict)
        #print(metrics.f1_score(y_train_pot,results))
        return metrics.f1_score(y_train_pot,results)
      
      adaline_weight = adaline_func([x[10:] for x in new_X_train_pot], target_function, w=adaline_weight)
      new_features = [generate_adaline_features(x[10:], adaline_weight) for x in new_X_test_pot]
      for i, n in enumerate(new_features):
        new_features[i] = np.concatenate((n,new_X_test_pot[i][10:]))
      new_X_test_pot = new_features
      results = clf.predict(new_X_test_pot)
      new_accuracy = metrics.f1_score(y_test_pot,results)
      print("old - ", old_accuracy, "new - ", new_accuracy)
    

  new_X_train = []
 
  for i,x in enumerate(new_X_train_1):
    new_X_train.append(np.concatenate((X_train_SOM_N[i],x, new_X_train_2[i], new_X_train_3[i])))


  new_X_test_1 = normalize(automatic_transformation(X_test, 'weights_1'))
  new_X_test_2 = normalize(automatic_transformation(X_test, 'weights_2'))
  new_X_test_3 = normalize(automatic_transformation(X_test, 'weights_3'))

  new_X_test = [np.concatenate((
      X_test[i],
      x,
      new_X_test_2[i],
      new_X_test_3[i]
  )) for i,x in enumerate(new_X_test_1)]

  print(new_X_test[0])
  ##Potencialização
  opt_new_X_train = [np.concatenate((
    generate_adaline_features(x, adaline_weight),x
    )) for x in new_X_train]

  opt_new_X_test = [np.concatenate((
    generate_adaline_features(x, adaline_weight),x
    )) for x in new_X_test]

  result_dict_normal = {}
  result_dict_desc = {}
  # clf = DecisionTreeClassifier()
  # clf = clf.fit(X_train,y_train)
  # clf.feature_importances_

  # results = clf.predict(X_test)
  # result_dict_normal["arvore"] = metrics.f1_score(y_test,results)


  # clf = DecisionTreeClassifier()
  # clf.fit(opt_new_X_train,y_train_SOM_N)

  # results = clf.predict(opt_new_X_test)
  # result_dict_desc["arvore"] = metrics.f1_score(y_test,results)

  from sklearn.ensemble import RandomForestClassifier
  from sklearn.model_selection import GridSearchCV
  from sklearn.model_selection import KFold
  clf = RandomForestClassifier()
  clf = GridSearchCV(estimator=clf, cv=KFold(10), param_grid={}, scoring='f1')
  clf.fit(X_train, y_train)
  results = clf.predict(X_test)
  result_dict_normal["randomforest"] = metrics.f1_score(y_test,results)

  clf =  RandomForestClassifier()
  clf.fit(opt_new_X_train, y_train_SOM_N)
  results = clf.predict(opt_new_X_test)
  result_dict_desc["randomforest"] = metrics.f1_score(y_test,results)
  print("F1 score", metrics.f1_score(y_test,results))
  print("Accuracy Score", metrics.accuracy_score(y_test,results))

  # from sklearn.neural_network import MLPClassifier
  # clf = MLPClassifier(solver='lbfgs', alpha=0.001,hidden_layer_sizes=(150,),, max_iter=10000)
  # clf.fit(X_train, y_train)
  # results = clf.predict(X_test)
  # result_dict_normal["rnn"] = metrics.f1_score(y_test,results)

  # clf = MLPClassifier(solver='lbfgs', alpha=0.001,hidden_layer_sizes=(150,),, max_iter=10000)
  # clf.fit(opt_new_X_train, y_train_SOM_N)
  # results = clf.predict(opt_new_X_test)
  # result_dict_desc["rnn"] = metrics.f1_score(y_test,results)
  # print("F1 score", metrics.f1_score(y_test,results))

  # from sklearn.neighbors import KNeighborsClassifier
  # clf=KNeighborsClassifier(n_neighbors=5)
  # clf.fit(X_train, y_train)
  # results = clf.predict(X_test)
  # result_dict_normal["knn"] = metrics.f1_score(y_test,results)

  # clf=KNeighborsClassifier(n_neighbors=5)
  # clf.fit(opt_new_X_train, y_train_SOM_N)
  # results = clf.predict(opt_new_X_test)
  # result_dict_desc["knn"] = metrics.f1_score(y_test,results)
  # print("Features normais")
  # print(result_dict_normal)
  # print("Features desconstruidas")
  # print(result_dict_desc)
  # accuracy_array_normal.append(result_dict_normal)
  # accuracy_array_desc.append(result_dict_desc)

import json
with open("normal.txt", 'w') as outfile:
    json.dump(accuracy_array_normal,outfile)
with open("desconstruida.txt", 'w') as outfile:
    json.dump(accuracy_array_desc,outfile)