# -*- coding: utf-8 -*-
"""SOM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mJe1Tmv6ZtIy0UGMYtFKce8Lw1EEVlza
"""

#!pip install SimpSOM

import pandas as pd

from sklearn.tree import  DecisionTreeClassifier,export_graphviz
from sklearn.model_selection import train_test_split
from sklearn import metrics
import numpy as np
import SimpSOM as sps
from sklearn.preprocessing import normalize
from sklearn.preprocessing import normalize
import random

def map_class(row):
  return row
  # if(row == "tested_negative"):
  #   return 0
  # return 1

df_diabetes = pd.read_csv("./datasets/letters.csv")
df_diabetes["class"] = df_diabetes["class"].apply(map_class)
df_diabetes.head()

accuracy_array_normal = []
accuracy_array_desc = []

for x in range(30):
  X_train, X_test, y_train, y_test = train_test_split(df_diabetes.drop('class',axis=1),df_diabetes['class'],test_size=0.3,stratify=df_diabetes['class'])
  X_train = normalize(X_train)
  X_test = normalize(X_test)
  X_train.shape,X_test.shape

  df_describe = pd.DataFrame(y_test)
  print(df_describe.describe())


  X_train_SOM_N, X_train_SOM, y_train_SOM_N, y_train_SOM = train_test_split(X_train,y_train,test_size=0.2, stratify=y_train)

  X_train_SOM_N.shape, X_train_SOM.shape

  net = sps.somNet(6, 6, X_train_SOM, PBC=True)
  net.train(0.01, 10000)
  net.save('weights_1')
 

  def automatic_transformation(dataframe,weights="flename_weights"):
    weights = np.load("./"+weights+".npy")
    new_data = []
    for data in dataframe:
      new_features = []
      for i,w in enumerate(weights):
        if i == 0:
          continue
        new_features.append(
            sum([x*data[i] for i,x in enumerate(w)])
        )
      new_data.append(np.concatenate(([],new_features)))
    return new_data


  new_X_train_1 = normalize(automatic_transformation(X_train_SOM_N,'weights_1'))

  net2 = sps.somNet(5, 5, X_train_SOM, PBC=True)
  net2.train(0.01, 10000)
  net2.save('weights_2')
  new_X_train_2 = normalize(automatic_transformation(X_train_SOM_N, "weights_2"))

  net3 = sps.somNet(4, 4, X_train_SOM, PBC=True)
  net3.train(0.01, 10000)
  net3.save('weights_3')

  new_X_train_3 = normalize(automatic_transformation(X_train_SOM_N, "weights_3"))

  def generate_adversarial_new_features(feature_type, qt):
    new_feature = []
      for x in range(0, qt):
        new_values = []
        for i in range(0,10):
          new_values.append(random.uniform(1,-1))
        new_feature.append(new_values)
    return new_feature

  for i in range(0, 10):
    ##construir if
      X_train_pot, X_test_pot, y_train_pot, y_test_pot = train_test_split(X_train_SOM,y_train_SOM,test_size=0.3,stratify=y_train_SOM)

      
      adversarial_train_features = generate_adversarial_new_features(feature_type="random", qt=len(X_train_pot))
      new_X_train_1_pot = normalize(automatic_transformation(X_train_pot, 'weights_1'))
      new_X_train_2_pot = normalize(automatic_transformation(X_train_pot, 'weights_2'))
      new_X_train_3_pot = normalize(automatic_transformation(X_train_pot, 'weights_3'))
      adversarial_test_features = generate_adversarial_new_features(feature_type="random", qt=len(X_test_pot))
      new_X_test_1_pot = normalize(automatic_transformation(X_test_pot, 'weights_1'))
      new_X_test_2_pot = normalize(automatic_transformation(X_test_pot, 'weights_2'))
      new_X_test_3_pot = normalize(automatic_transformation(X_test_pot, 'weights_3'))
      new_X_train_pot = []
      for i,x in enumerate(adversarial_train_features):
        new_X_train_pot.append(np.concatenate((
          x,
          X_train_pot[i],
          new_X_train_1_pot[i],
          new_X_train_2_pot[i],
          new_X_train_3_pot[i]
        )))
      new_X_test_pot = []
      for i,x in enumerate(adversarial_test_features):
        new_X_test_pot.append(np.concatenate((
          x,
          X_test_pot[i],
          new_X_test_1_pot[i],
          new_X_test_2_pot[i],
          new_X_test_3_pot[i]
        )))
      from sklearn.neural_network import MLPClassifier

      clf = MLPClassifier(solver='lbfgs', alpha=0.001,hidden_layer_sizes=(150,),random_state=1, max_iter=10000)
      clf.fit(new_X_train, y_train_SOM_N)
      results = clf.predict(new_X_test)
      result_dict_desc["rnn"] = metrics.accuracy_score(y_test,results)
      
  new_X_train = []
 
  for i,x in enumerate(new_X_train_1):
    new_X_train.append(np.concatenate((X_train_SOM_N[i],x, new_X_train_2[i], new_X_train_3[i])))


  new_X_test_1 = normalize(automatic_transformation(X_test, 'weights_1'))
  new_X_test_2 = normalize(automatic_transformation(X_test, 'weights_2'))
  new_X_test_3 = normalize(automatic_transformation(X_test, 'weights_3'))

  new_X_test = [np.concatenate((
      X_test[i],
      x,
      new_X_test_2[i],
      new_X_test_3[i]
  )) for i,x in enumerate(new_X_test_1)]

  print(new_X_test[0])
  result_dict_normal = {}
  result_dict_desc = {}
  # clf = DecisionTreeClassifier(random_state=1)
  # clf = clf.fit(X_train,y_train)
  # clf.feature_importances_

  # results = clf.predict(X_test)
  # result_dict_normal["arvore"] = metrics.accuracy_score(y_test,results)


  # clf = DecisionTreeClassifier(random_state=1)
  # clf.fit(new_X_train,y_train_SOM_N)

  # results = clf.predict(new_X_test)
  # result_dict_desc["arvore"] = metrics.accuracy_score(y_test,results)

  # from sklearn.ensemble import RandomForestClassifier
  # clf = RandomForestClassifier(random_state=1)
  # clf.fit(X_train, y_train)
  # results = clf.predict(X_test)
  # result_dict_normal["randomforest"] = metrics.accuracy_score(y_test,results)

  # clf =  RandomForestClassifier(random_state=1)
  # clf.fit(new_X_train, y_train_SOM_N)
  # results = clf.predict(new_X_test)
  # result_dict_desc["randomforest"] = metrics.accuracy_score(y_test,results)

  from sklearn.neural_network import MLPClassifier
  clf = MLPClassifier(solver='lbfgs', alpha=0.001,hidden_layer_sizes=(150,),random_state=1, max_iter=10000)
  clf.fit(X_train, y_train)
  results = clf.predict(X_test)
  result_dict_normal["rnn"] = metrics.accuracy_score(y_test,results)

  clf = MLPClassifier(solver='lbfgs', alpha=0.001,hidden_layer_sizes=(150,),random_state=1, max_iter=10000)
  clf.fit(new_X_train, y_train_SOM_N)
  results = clf.predict(new_X_test)
  result_dict_desc["rnn"] = metrics.accuracy_score(y_test,results)

  # from sklearn.neighbors import KNeighborsClassifier
  # clf=KNeighborsClassifier(n_neighbors=5)
  # clf.fit(X_train, y_train)
  # results = clf.predict(X_test)
  # result_dict_normal["knn"] = metrics.accuracy_score(y_test,results)

  # clf=KNeighborsClassifier(n_neighbors=5)
  # clf.fit(new_X_train, y_train_SOM_N)
  # results = clf.predict(new_X_test)
  # result_dict_desc["knn"] = metrics.accuracy_score(y_test,results)
  # print("Features normais")
  # print(result_dict_normal)
  # print("Features desconstruidas")
  # print(result_dict_desc)
  # accuracy_array_normal.append(result_dict_normal)
  # accuracy_array_desc.append(result_dict_desc)

import json
with open("normal.txt", 'w') as outfile:
    json.dump(accuracy_array_normal,outfile)
with open("desconstruida.txt", 'w') as outfile:
    json.dump(accuracy_array_desc,outfile)